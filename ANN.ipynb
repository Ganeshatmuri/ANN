{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"Churn_Modelling.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>15634602</td>\n",
       "      <td>Hargrave</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>15647311</td>\n",
       "      <td>Hill</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>15619304</td>\n",
       "      <td>Onio</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>15701354</td>\n",
       "      <td>Boni</td>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>15737888</td>\n",
       "      <td>Mitchell</td>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RowNumber  CustomerId   Surname  CreditScore Geography  Gender  Age  \\\n",
       "0          1    15634602  Hargrave          619    France  Female   42   \n",
       "1          2    15647311      Hill          608     Spain  Female   41   \n",
       "2          3    15619304      Onio          502    France  Female   42   \n",
       "3          4    15701354      Boni          699    France  Female   39   \n",
       "4          5    15737888  Mitchell          850     Spain  Female   43   \n",
       "\n",
       "   Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "0       2       0.00              1          1               1   \n",
       "1       1   83807.86              1          0               1   \n",
       "2       8  159660.80              3          1               0   \n",
       "3       1       0.00              2          0               0   \n",
       "4       2  125510.82              1          1               1   \n",
       "\n",
       "   EstimatedSalary  Exited  \n",
       "0        101348.88       1  \n",
       "1        112542.58       0  \n",
       "2        113931.57       1  \n",
       "3         93826.63       0  \n",
       "4         79084.10       0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df.iloc[:,3:13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>771</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>39</td>\n",
       "      <td>5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>96270.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>516</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>35</td>\n",
       "      <td>10</td>\n",
       "      <td>57369.61</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101699.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>709</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>36</td>\n",
       "      <td>7</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>42085.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>772</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Male</td>\n",
       "      <td>42</td>\n",
       "      <td>3</td>\n",
       "      <td>75075.31</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>92888.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>792</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>28</td>\n",
       "      <td>4</td>\n",
       "      <td>130142.79</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38190.78</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      CreditScore Geography  Gender  Age  Tenure    Balance  NumOfProducts  \\\n",
       "0             619    France  Female   42       2       0.00              1   \n",
       "1             608     Spain  Female   41       1   83807.86              1   \n",
       "2             502    France  Female   42       8  159660.80              3   \n",
       "3             699    France  Female   39       1       0.00              2   \n",
       "4             850     Spain  Female   43       2  125510.82              1   \n",
       "...           ...       ...     ...  ...     ...        ...            ...   \n",
       "9995          771    France    Male   39       5       0.00              2   \n",
       "9996          516    France    Male   35      10   57369.61              1   \n",
       "9997          709    France  Female   36       7       0.00              1   \n",
       "9998          772   Germany    Male   42       3   75075.31              2   \n",
       "9999          792    France  Female   28       4  130142.79              1   \n",
       "\n",
       "      HasCrCard  IsActiveMember  EstimatedSalary  \n",
       "0             1               1        101348.88  \n",
       "1             0               1        112542.58  \n",
       "2             1               0        113931.57  \n",
       "3             0               0         93826.63  \n",
       "4             1               1         79084.10  \n",
       "...         ...             ...              ...  \n",
       "9995          1               0         96270.64  \n",
       "9996          1               1        101699.77  \n",
       "9997          0               1         42085.58  \n",
       "9998          1               0         92888.52  \n",
       "9999          1               0         38190.78  \n",
       "\n",
       "[10000 rows x 10 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=df.iloc[:,13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       1\n",
       "1       0\n",
       "2       1\n",
       "3       0\n",
       "4       0\n",
       "       ..\n",
       "9995    0\n",
       "9996    0\n",
       "9997    1\n",
       "9998    1\n",
       "9999    0\n",
       "Name: Exited, Length: 10000, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "geography=pd.get_dummies(X['Geography'],drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Germany</th>\n",
       "      <th>Spain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Germany  Spain\n",
       "0           0      0\n",
       "1           0      1\n",
       "2           0      0\n",
       "3           0      0\n",
       "4           0      1\n",
       "...       ...    ...\n",
       "9995        0      0\n",
       "9996        0      0\n",
       "9997        0      0\n",
       "9998        1      0\n",
       "9999        0      0\n",
       "\n",
       "[10000 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "geography"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "gender=pd.get_dummies(X['Gender'],drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Male\n",
       "0        0\n",
       "1        0\n",
       "2        0\n",
       "3        0\n",
       "4        0\n",
       "...    ...\n",
       "9995     1\n",
       "9996     1\n",
       "9997     0\n",
       "9998     1\n",
       "9999     0\n",
       "\n",
       "[10000 rows x 1 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=pd.concat([X,gender,geography],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Male</th>\n",
       "      <th>Germany</th>\n",
       "      <th>Spain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>771</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>39</td>\n",
       "      <td>5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>96270.64</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>516</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>35</td>\n",
       "      <td>10</td>\n",
       "      <td>57369.61</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101699.77</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>709</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>36</td>\n",
       "      <td>7</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>42085.58</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>772</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Male</td>\n",
       "      <td>42</td>\n",
       "      <td>3</td>\n",
       "      <td>75075.31</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>92888.52</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>792</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>28</td>\n",
       "      <td>4</td>\n",
       "      <td>130142.79</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38190.78</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      CreditScore Geography  Gender  Age  Tenure    Balance  NumOfProducts  \\\n",
       "0             619    France  Female   42       2       0.00              1   \n",
       "1             608     Spain  Female   41       1   83807.86              1   \n",
       "2             502    France  Female   42       8  159660.80              3   \n",
       "3             699    France  Female   39       1       0.00              2   \n",
       "4             850     Spain  Female   43       2  125510.82              1   \n",
       "...           ...       ...     ...  ...     ...        ...            ...   \n",
       "9995          771    France    Male   39       5       0.00              2   \n",
       "9996          516    France    Male   35      10   57369.61              1   \n",
       "9997          709    France  Female   36       7       0.00              1   \n",
       "9998          772   Germany    Male   42       3   75075.31              2   \n",
       "9999          792    France  Female   28       4  130142.79              1   \n",
       "\n",
       "      HasCrCard  IsActiveMember  EstimatedSalary  Male  Germany  Spain  \n",
       "0             1               1        101348.88     0        0      0  \n",
       "1             0               1        112542.58     0        0      1  \n",
       "2             1               0        113931.57     0        0      0  \n",
       "3             0               0         93826.63     0        0      0  \n",
       "4             1               1         79084.10     0        0      1  \n",
       "...         ...             ...              ...   ...      ...    ...  \n",
       "9995          1               0         96270.64     1        0      0  \n",
       "9996          1               1        101699.77     1        0      0  \n",
       "9997          0               1         42085.58     0        0      0  \n",
       "9998          1               0         92888.52     1        1      0  \n",
       "9999          1               0         38190.78     0        0      0  \n",
       "\n",
       "[10000 rows x 13 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=X.drop(['Geography','Gender'],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Male</th>\n",
       "      <th>Germany</th>\n",
       "      <th>Spain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>608</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>502</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>699</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>850</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>771</td>\n",
       "      <td>39</td>\n",
       "      <td>5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>96270.64</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>516</td>\n",
       "      <td>35</td>\n",
       "      <td>10</td>\n",
       "      <td>57369.61</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101699.77</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>709</td>\n",
       "      <td>36</td>\n",
       "      <td>7</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>42085.58</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>772</td>\n",
       "      <td>42</td>\n",
       "      <td>3</td>\n",
       "      <td>75075.31</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>92888.52</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>792</td>\n",
       "      <td>28</td>\n",
       "      <td>4</td>\n",
       "      <td>130142.79</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38190.78</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      CreditScore  Age  Tenure    Balance  NumOfProducts  HasCrCard  \\\n",
       "0             619   42       2       0.00              1          1   \n",
       "1             608   41       1   83807.86              1          0   \n",
       "2             502   42       8  159660.80              3          1   \n",
       "3             699   39       1       0.00              2          0   \n",
       "4             850   43       2  125510.82              1          1   \n",
       "...           ...  ...     ...        ...            ...        ...   \n",
       "9995          771   39       5       0.00              2          1   \n",
       "9996          516   35      10   57369.61              1          1   \n",
       "9997          709   36       7       0.00              1          0   \n",
       "9998          772   42       3   75075.31              2          1   \n",
       "9999          792   28       4  130142.79              1          1   \n",
       "\n",
       "      IsActiveMember  EstimatedSalary  Male  Germany  Spain  \n",
       "0                  1        101348.88     0        0      0  \n",
       "1                  1        112542.58     0        0      1  \n",
       "2                  0        113931.57     0        0      0  \n",
       "3                  0         93826.63     0        0      0  \n",
       "4                  1         79084.10     0        0      1  \n",
       "...              ...              ...   ...      ...    ...  \n",
       "9995               0         96270.64     1        0      0  \n",
       "9996               1        101699.77     1        0      0  \n",
       "9997               1         42085.58     0        0      0  \n",
       "9998               0         92888.52     1        1      0  \n",
       "9999               0         38190.78     0        0      0  \n",
       "\n",
       "[10000 rows x 11 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc=StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=sc.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.32622142,  0.29351742, -1.04175968, ..., -1.09598752,\n",
       "        -0.57873591, -0.57380915],\n",
       "       [-0.44003595,  0.19816383, -1.38753759, ..., -1.09598752,\n",
       "        -0.57873591,  1.74273971],\n",
       "       [-1.53679418,  0.29351742,  1.03290776, ..., -1.09598752,\n",
       "        -0.57873591, -0.57380915],\n",
       "       ...,\n",
       "       [ 0.60498839, -0.27860412,  0.68712986, ..., -1.09598752,\n",
       "        -0.57873591, -0.57380915],\n",
       "       [ 1.25683526,  0.29351742, -0.69598177, ...,  0.91241915,\n",
       "         1.72790383, -0.57380915],\n",
       "       [ 1.46377078, -1.04143285, -0.35020386, ..., -1.09598752,\n",
       "        -0.57873591, -0.57380915]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=110)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier=Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.add(Dense(units=10,kernel_initializer='he_uniform',activation='relu',input_dim=11))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.add(Dense(units=6,kernel_initializer='he_uniform',activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.add(Dense(units=1,kernel_initializer='glorot_uniform',activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 10)                120       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 6)                 66        \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 7         \n",
      "=================================================================\n",
      "Total params: 193\n",
      "Trainable params: 193\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "classifier.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "536/536 [==============================] - 1s 1ms/step - loss: 0.5476 - accuracy: 0.7598 - val_loss: 0.4773 - val_accuracy: 0.7986\n",
      "Epoch 2/100\n",
      "536/536 [==============================] - 1s 1ms/step - loss: 0.4548 - accuracy: 0.8046 - val_loss: 0.4397 - val_accuracy: 0.8092\n",
      "Epoch 3/100\n",
      "536/536 [==============================] - 1s 1ms/step - loss: 0.4341 - accuracy: 0.8175 - val_loss: 0.4247 - val_accuracy: 0.8179\n",
      "Epoch 4/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.4235 - accuracy: 0.8203 - val_loss: 0.4146 - val_accuracy: 0.8205\n",
      "Epoch 5/100\n",
      "536/536 [==============================] - 1s 1ms/step - loss: 0.4149 - accuracy: 0.8248 - val_loss: 0.4046 - val_accuracy: 0.8213\n",
      "Epoch 6/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.4069 - accuracy: 0.8274 - val_loss: 0.3980 - val_accuracy: 0.8251\n",
      "Epoch 7/100\n",
      "536/536 [==============================] - 1s 1ms/step - loss: 0.3992 - accuracy: 0.8341 - val_loss: 0.3898 - val_accuracy: 0.8315\n",
      "Epoch 8/100\n",
      "536/536 [==============================] - 1s 1ms/step - loss: 0.3912 - accuracy: 0.8371 - val_loss: 0.3818 - val_accuracy: 0.8353\n",
      "Epoch 9/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3833 - accuracy: 0.8429 - val_loss: 0.3739 - val_accuracy: 0.8398\n",
      "Epoch 10/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3755 - accuracy: 0.8446 - val_loss: 0.3662 - val_accuracy: 0.8432\n",
      "Epoch 11/100\n",
      "536/536 [==============================] - 1s 1ms/step - loss: 0.3690 - accuracy: 0.8503 - val_loss: 0.3587 - val_accuracy: 0.8455\n",
      "Epoch 12/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3634 - accuracy: 0.8507 - val_loss: 0.3570 - val_accuracy: 0.8493\n",
      "Epoch 13/100\n",
      "536/536 [==============================] - 1s 1ms/step - loss: 0.3612 - accuracy: 0.8517 - val_loss: 0.3485 - val_accuracy: 0.8527\n",
      "Epoch 14/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3587 - accuracy: 0.8539 - val_loss: 0.3484 - val_accuracy: 0.8554\n",
      "Epoch 15/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3560 - accuracy: 0.8556 - val_loss: 0.3452 - val_accuracy: 0.8565\n",
      "Epoch 16/100\n",
      "536/536 [==============================] - 1s 1ms/step - loss: 0.3543 - accuracy: 0.8572 - val_loss: 0.3444 - val_accuracy: 0.8565\n",
      "Epoch 17/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3533 - accuracy: 0.8543 - val_loss: 0.3421 - val_accuracy: 0.8591\n",
      "Epoch 18/100\n",
      "536/536 [==============================] - 1s 1ms/step - loss: 0.3523 - accuracy: 0.8584 - val_loss: 0.3393 - val_accuracy: 0.8576\n",
      "Epoch 19/100\n",
      "536/536 [==============================] - 1s 1ms/step - loss: 0.3504 - accuracy: 0.8586 - val_loss: 0.3409 - val_accuracy: 0.8588\n",
      "Epoch 20/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3490 - accuracy: 0.8617 - val_loss: 0.3398 - val_accuracy: 0.8603\n",
      "Epoch 21/100\n",
      "536/536 [==============================] - 1s 1ms/step - loss: 0.3480 - accuracy: 0.8586 - val_loss: 0.3380 - val_accuracy: 0.8614\n",
      "Epoch 22/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3465 - accuracy: 0.8600 - val_loss: 0.3368 - val_accuracy: 0.8610\n",
      "Epoch 23/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3455 - accuracy: 0.8591 - val_loss: 0.3396 - val_accuracy: 0.8595\n",
      "Epoch 24/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3452 - accuracy: 0.8593 - val_loss: 0.3332 - val_accuracy: 0.8599\n",
      "Epoch 25/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3441 - accuracy: 0.8606 - val_loss: 0.3368 - val_accuracy: 0.8599\n",
      "Epoch 26/100\n",
      "536/536 [==============================] - 1s 1ms/step - loss: 0.3435 - accuracy: 0.8604 - val_loss: 0.3332 - val_accuracy: 0.8614\n",
      "Epoch 27/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3425 - accuracy: 0.8617 - val_loss: 0.3341 - val_accuracy: 0.8603\n",
      "Epoch 28/100\n",
      "536/536 [==============================] - 1s 1ms/step - loss: 0.3417 - accuracy: 0.8608 - val_loss: 0.3338 - val_accuracy: 0.8614\n",
      "Epoch 29/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3412 - accuracy: 0.8642 - val_loss: 0.3327 - val_accuracy: 0.8618\n",
      "Epoch 30/100\n",
      "536/536 [==============================] - 1s 1ms/step - loss: 0.3412 - accuracy: 0.8636 - val_loss: 0.3330 - val_accuracy: 0.8569\n",
      "Epoch 31/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3396 - accuracy: 0.8628 - val_loss: 0.3302 - val_accuracy: 0.8622\n",
      "Epoch 32/100\n",
      "536/536 [==============================] - 1s 1ms/step - loss: 0.3401 - accuracy: 0.8628 - val_loss: 0.3294 - val_accuracy: 0.8614\n",
      "Epoch 33/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3391 - accuracy: 0.8647 - val_loss: 0.3292 - val_accuracy: 0.8595\n",
      "Epoch 34/100\n",
      "536/536 [==============================] - 1s 1ms/step - loss: 0.3386 - accuracy: 0.8640 - val_loss: 0.3289 - val_accuracy: 0.8626\n",
      "Epoch 35/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3378 - accuracy: 0.8621 - val_loss: 0.3302 - val_accuracy: 0.8618\n",
      "Epoch 36/100\n",
      "536/536 [==============================] - 1s 1ms/step - loss: 0.3382 - accuracy: 0.8658 - val_loss: 0.3301 - val_accuracy: 0.8614\n",
      "Epoch 37/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3377 - accuracy: 0.8649 - val_loss: 0.3291 - val_accuracy: 0.8652\n",
      "Epoch 38/100\n",
      "536/536 [==============================] - 1s 1ms/step - loss: 0.3368 - accuracy: 0.8670 - val_loss: 0.3302 - val_accuracy: 0.8633\n",
      "Epoch 39/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3363 - accuracy: 0.8658 - val_loss: 0.3318 - val_accuracy: 0.8648\n",
      "Epoch 40/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3371 - accuracy: 0.8647 - val_loss: 0.3292 - val_accuracy: 0.8618\n",
      "Epoch 41/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3358 - accuracy: 0.8658 - val_loss: 0.3284 - val_accuracy: 0.8637\n",
      "Epoch 42/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3355 - accuracy: 0.8660 - val_loss: 0.3274 - val_accuracy: 0.8641\n",
      "Epoch 43/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3346 - accuracy: 0.8649 - val_loss: 0.3301 - val_accuracy: 0.8652\n",
      "Epoch 44/100\n",
      "536/536 [==============================] - 1s 1ms/step - loss: 0.3351 - accuracy: 0.8664 - val_loss: 0.3305 - val_accuracy: 0.8603\n",
      "Epoch 45/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3350 - accuracy: 0.8662 - val_loss: 0.3286 - val_accuracy: 0.8603\n",
      "Epoch 46/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3349 - accuracy: 0.8656 - val_loss: 0.3286 - val_accuracy: 0.8637\n",
      "Epoch 47/100\n",
      "536/536 [==============================] - 1s 1ms/step - loss: 0.3345 - accuracy: 0.8666 - val_loss: 0.3294 - val_accuracy: 0.8629\n",
      "Epoch 48/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3337 - accuracy: 0.8653 - val_loss: 0.3322 - val_accuracy: 0.8607\n",
      "Epoch 49/100\n",
      "536/536 [==============================] - 1s 1ms/step - loss: 0.3341 - accuracy: 0.8658 - val_loss: 0.3294 - val_accuracy: 0.8648\n",
      "Epoch 50/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3337 - accuracy: 0.8647 - val_loss: 0.3312 - val_accuracy: 0.8641\n",
      "Epoch 51/100\n",
      "536/536 [==============================] - 1s 1ms/step - loss: 0.3322 - accuracy: 0.8660 - val_loss: 0.3247 - val_accuracy: 0.8637\n",
      "Epoch 52/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3332 - accuracy: 0.8655 - val_loss: 0.3293 - val_accuracy: 0.8610\n",
      "Epoch 53/100\n",
      "536/536 [==============================] - 1s 1ms/step - loss: 0.3329 - accuracy: 0.8677 - val_loss: 0.3272 - val_accuracy: 0.8610\n",
      "Epoch 54/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3322 - accuracy: 0.8653 - val_loss: 0.3244 - val_accuracy: 0.8622\n",
      "Epoch 55/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3320 - accuracy: 0.8656 - val_loss: 0.3257 - val_accuracy: 0.8618\n",
      "Epoch 56/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3326 - accuracy: 0.8640 - val_loss: 0.3285 - val_accuracy: 0.8644\n",
      "Epoch 57/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3328 - accuracy: 0.8656 - val_loss: 0.3273 - val_accuracy: 0.8641\n",
      "Epoch 58/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3313 - accuracy: 0.8668 - val_loss: 0.3279 - val_accuracy: 0.8644\n",
      "Epoch 59/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3321 - accuracy: 0.8662 - val_loss: 0.3281 - val_accuracy: 0.8618\n",
      "Epoch 60/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3320 - accuracy: 0.8694 - val_loss: 0.3272 - val_accuracy: 0.8629\n",
      "Epoch 61/100\n",
      "536/536 [==============================] - 1s 1ms/step - loss: 0.3315 - accuracy: 0.8668 - val_loss: 0.3257 - val_accuracy: 0.8652\n",
      "Epoch 62/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3313 - accuracy: 0.8673 - val_loss: 0.3260 - val_accuracy: 0.8637\n",
      "Epoch 63/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3317 - accuracy: 0.8653 - val_loss: 0.3244 - val_accuracy: 0.8629\n",
      "Epoch 64/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3305 - accuracy: 0.8666 - val_loss: 0.3234 - val_accuracy: 0.8637\n",
      "Epoch 65/100\n",
      "536/536 [==============================] - 1s 1ms/step - loss: 0.3310 - accuracy: 0.8666 - val_loss: 0.3267 - val_accuracy: 0.8626\n",
      "Epoch 66/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3304 - accuracy: 0.8666 - val_loss: 0.3264 - val_accuracy: 0.8610\n",
      "Epoch 67/100\n",
      "536/536 [==============================] - 1s 1ms/step - loss: 0.3308 - accuracy: 0.8656 - val_loss: 0.3276 - val_accuracy: 0.8626\n",
      "Epoch 68/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3304 - accuracy: 0.8643 - val_loss: 0.3271 - val_accuracy: 0.8618\n",
      "Epoch 69/100\n",
      "536/536 [==============================] - 1s 1ms/step - loss: 0.3305 - accuracy: 0.8671 - val_loss: 0.3265 - val_accuracy: 0.8626\n",
      "Epoch 70/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3304 - accuracy: 0.8660 - val_loss: 0.3262 - val_accuracy: 0.8618\n",
      "Epoch 71/100\n",
      "536/536 [==============================] - 1s 1ms/step - loss: 0.3298 - accuracy: 0.8671 - val_loss: 0.3273 - val_accuracy: 0.8614\n",
      "Epoch 72/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3305 - accuracy: 0.8666 - val_loss: 0.3257 - val_accuracy: 0.8633\n",
      "Epoch 73/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3302 - accuracy: 0.8642 - val_loss: 0.3264 - val_accuracy: 0.8618\n",
      "Epoch 74/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3295 - accuracy: 0.8673 - val_loss: 0.3269 - val_accuracy: 0.8644\n",
      "Epoch 75/100\n",
      "536/536 [==============================] - 1s 1ms/step - loss: 0.3301 - accuracy: 0.8653 - val_loss: 0.3253 - val_accuracy: 0.8626\n",
      "Epoch 76/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3305 - accuracy: 0.8660 - val_loss: 0.3252 - val_accuracy: 0.8648\n",
      "Epoch 77/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3296 - accuracy: 0.8664 - val_loss: 0.3255 - val_accuracy: 0.8656\n",
      "Epoch 78/100\n",
      "536/536 [==============================] - 1s 1ms/step - loss: 0.3296 - accuracy: 0.8653 - val_loss: 0.3284 - val_accuracy: 0.8626\n",
      "Epoch 79/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3292 - accuracy: 0.8660 - val_loss: 0.3252 - val_accuracy: 0.8633\n",
      "Epoch 80/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3294 - accuracy: 0.8643 - val_loss: 0.3247 - val_accuracy: 0.8633\n",
      "Epoch 81/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3295 - accuracy: 0.8660 - val_loss: 0.3257 - val_accuracy: 0.8614\n",
      "Epoch 82/100\n",
      "536/536 [==============================] - 1s 1ms/step - loss: 0.3284 - accuracy: 0.8655 - val_loss: 0.3282 - val_accuracy: 0.8622\n",
      "Epoch 83/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3285 - accuracy: 0.8686 - val_loss: 0.3335 - val_accuracy: 0.8648\n",
      "Epoch 84/100\n",
      "536/536 [==============================] - 1s 1ms/step - loss: 0.3289 - accuracy: 0.8666 - val_loss: 0.3267 - val_accuracy: 0.8652\n",
      "Epoch 85/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3294 - accuracy: 0.8664 - val_loss: 0.3281 - val_accuracy: 0.8641\n",
      "Epoch 86/100\n",
      "536/536 [==============================] - 1s 1ms/step - loss: 0.3292 - accuracy: 0.8670 - val_loss: 0.3280 - val_accuracy: 0.8618\n",
      "Epoch 87/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3294 - accuracy: 0.8651 - val_loss: 0.3295 - val_accuracy: 0.8644\n",
      "Epoch 88/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3294 - accuracy: 0.8651 - val_loss: 0.3270 - val_accuracy: 0.8637\n",
      "Epoch 89/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3293 - accuracy: 0.8664 - val_loss: 0.3265 - val_accuracy: 0.8626\n",
      "Epoch 90/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3288 - accuracy: 0.8643 - val_loss: 0.3260 - val_accuracy: 0.8633\n",
      "Epoch 91/100\n",
      "536/536 [==============================] - 1s 1ms/step - loss: 0.3287 - accuracy: 0.8632 - val_loss: 0.3282 - val_accuracy: 0.8633\n",
      "Epoch 92/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3285 - accuracy: 0.8671 - val_loss: 0.3322 - val_accuracy: 0.8633\n",
      "Epoch 93/100\n",
      "536/536 [==============================] - 1s 1ms/step - loss: 0.3288 - accuracy: 0.8671 - val_loss: 0.3278 - val_accuracy: 0.8637\n",
      "Epoch 94/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3284 - accuracy: 0.8664 - val_loss: 0.3275 - val_accuracy: 0.8644\n",
      "Epoch 95/100\n",
      "536/536 [==============================] - 1s 1ms/step - loss: 0.3288 - accuracy: 0.8655 - val_loss: 0.3271 - val_accuracy: 0.8626\n",
      "Epoch 96/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3291 - accuracy: 0.8683 - val_loss: 0.3272 - val_accuracy: 0.8633\n",
      "Epoch 97/100\n",
      "536/536 [==============================] - 1s 1ms/step - loss: 0.3287 - accuracy: 0.8692 - val_loss: 0.3277 - val_accuracy: 0.8629\n",
      "Epoch 98/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3290 - accuracy: 0.8668 - val_loss: 0.3288 - val_accuracy: 0.8629\n",
      "Epoch 99/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3286 - accuracy: 0.8671 - val_loss: 0.3264 - val_accuracy: 0.8622\n",
      "Epoch 100/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3283 - accuracy: 0.8681 - val_loss: 0.3281 - val_accuracy: 0.8637\n"
     ]
    }
   ],
   "source": [
    "model_history=classifier.fit(X_train,y_train,validation_split=0.33,batch_size=10,epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_history.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.05301529],\n",
       "       [0.9776197 ],\n",
       "       [0.17716646],\n",
       "       ...,\n",
       "       [0.09274381],\n",
       "       [0.89244556],\n",
       "       [0.06093729]], dtype=float32)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=(y_pred>0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       ...,\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix,accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm=confusion_matrix(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1546,   43],\n",
       "       [ 230,  181]], dtype=int64)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8635"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.add(Dense(units=10,kernel_initializer='he_normal',activation='relu',input_dim=11))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.add(Dense(units=20,kernel_initializer='he_normal',activation='relu',input_dim=11))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.add(Dense(units=15,kernel_initializer='he_normal',activation='relu',input_dim=11))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.add(Dense(units=1,kernel_initializer='glorot_uniform',activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 10)                120       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 6)                 66        \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 7         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                20        \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 20)                220       \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 15)                315       \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1)                 16        \n",
      "=================================================================\n",
      "Total params: 764\n",
      "Trainable params: 764\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "classifier.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "536/536 [==============================] - 1s 3ms/step - loss: 0.5435 - accuracy: 0.7964 - val_loss: 0.5075 - val_accuracy: 0.7974\n",
      "Epoch 2/100\n",
      "536/536 [==============================] - 1s 1ms/step - loss: 0.5071 - accuracy: 0.7964 - val_loss: 0.5054 - val_accuracy: 0.7974\n",
      "Epoch 3/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.5061 - accuracy: 0.7964 - val_loss: 0.5054 - val_accuracy: 0.7974\n",
      "Epoch 4/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.4741 - accuracy: 0.8000 - val_loss: 0.4367 - val_accuracy: 0.8289\n",
      "Epoch 5/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.4328 - accuracy: 0.8281 - val_loss: 0.4246 - val_accuracy: 0.8353\n",
      "Epoch 6/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.4242 - accuracy: 0.8334 - val_loss: 0.4198 - val_accuracy: 0.8353\n",
      "Epoch 7/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.4201 - accuracy: 0.8373 - val_loss: 0.4196 - val_accuracy: 0.8342\n",
      "Epoch 8/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.4175 - accuracy: 0.8414 - val_loss: 0.4169 - val_accuracy: 0.8372\n",
      "Epoch 9/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.4154 - accuracy: 0.8414 - val_loss: 0.4184 - val_accuracy: 0.8357\n",
      "Epoch 10/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.4135 - accuracy: 0.8403 - val_loss: 0.4179 - val_accuracy: 0.8368\n",
      "Epoch 11/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.4122 - accuracy: 0.8418 - val_loss: 0.4152 - val_accuracy: 0.8364\n",
      "Epoch 12/100\n",
      "536/536 [==============================] - 1s 1ms/step - loss: 0.4115 - accuracy: 0.8418 - val_loss: 0.4164 - val_accuracy: 0.8357\n",
      "Epoch 13/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.4101 - accuracy: 0.8429 - val_loss: 0.4168 - val_accuracy: 0.8368\n",
      "Epoch 14/100\n",
      "536/536 [==============================] - 1s 1ms/step - loss: 0.4097 - accuracy: 0.8421 - val_loss: 0.4131 - val_accuracy: 0.8360\n",
      "Epoch 15/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.4084 - accuracy: 0.8442 - val_loss: 0.4127 - val_accuracy: 0.8368\n",
      "Epoch 16/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.4076 - accuracy: 0.8444 - val_loss: 0.4138 - val_accuracy: 0.8353\n",
      "Epoch 17/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.4064 - accuracy: 0.8425 - val_loss: 0.4109 - val_accuracy: 0.8376\n",
      "Epoch 18/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.4043 - accuracy: 0.8418 - val_loss: 0.4091 - val_accuracy: 0.8376\n",
      "Epoch 19/100\n",
      "536/536 [==============================] - 1s 1ms/step - loss: 0.4013 - accuracy: 0.8442 - val_loss: 0.4068 - val_accuracy: 0.8357\n",
      "Epoch 20/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3971 - accuracy: 0.8429 - val_loss: 0.4056 - val_accuracy: 0.8357\n",
      "Epoch 21/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3879 - accuracy: 0.8447 - val_loss: 0.3861 - val_accuracy: 0.8387\n",
      "Epoch 22/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3757 - accuracy: 0.8502 - val_loss: 0.3700 - val_accuracy: 0.8470\n",
      "Epoch 23/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3656 - accuracy: 0.8559 - val_loss: 0.3647 - val_accuracy: 0.8523\n",
      "Epoch 24/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3599 - accuracy: 0.8586 - val_loss: 0.3536 - val_accuracy: 0.8508\n",
      "Epoch 25/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3541 - accuracy: 0.8632 - val_loss: 0.3482 - val_accuracy: 0.8554\n",
      "Epoch 26/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3503 - accuracy: 0.8578 - val_loss: 0.3433 - val_accuracy: 0.8614\n",
      "Epoch 27/100\n",
      "536/536 [==============================] - 1s 1ms/step - loss: 0.3481 - accuracy: 0.8602 - val_loss: 0.3412 - val_accuracy: 0.8622\n",
      "Epoch 28/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3443 - accuracy: 0.8628 - val_loss: 0.3458 - val_accuracy: 0.8607\n",
      "Epoch 29/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3447 - accuracy: 0.8642 - val_loss: 0.3378 - val_accuracy: 0.8644\n",
      "Epoch 30/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3432 - accuracy: 0.8632 - val_loss: 0.3393 - val_accuracy: 0.8599\n",
      "Epoch 31/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3422 - accuracy: 0.8653 - val_loss: 0.3367 - val_accuracy: 0.8641\n",
      "Epoch 32/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3412 - accuracy: 0.8684 - val_loss: 0.3376 - val_accuracy: 0.8629\n",
      "Epoch 33/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3396 - accuracy: 0.8660 - val_loss: 0.3378 - val_accuracy: 0.8622\n",
      "Epoch 34/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3379 - accuracy: 0.8677 - val_loss: 0.3342 - val_accuracy: 0.8663\n",
      "Epoch 35/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3373 - accuracy: 0.8675 - val_loss: 0.3350 - val_accuracy: 0.8637\n",
      "Epoch 36/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3361 - accuracy: 0.8686 - val_loss: 0.3440 - val_accuracy: 0.8607\n",
      "Epoch 37/100\n",
      "536/536 [==============================] - 1s 1ms/step - loss: 0.3369 - accuracy: 0.8690 - val_loss: 0.3358 - val_accuracy: 0.8660\n",
      "Epoch 38/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3352 - accuracy: 0.8690 - val_loss: 0.3363 - val_accuracy: 0.8663\n",
      "Epoch 39/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3344 - accuracy: 0.8679 - val_loss: 0.3342 - val_accuracy: 0.8637\n",
      "Epoch 40/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3339 - accuracy: 0.8681 - val_loss: 0.3346 - val_accuracy: 0.8656\n",
      "Epoch 41/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3335 - accuracy: 0.8692 - val_loss: 0.3330 - val_accuracy: 0.8648\n",
      "Epoch 42/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3325 - accuracy: 0.8670 - val_loss: 0.3345 - val_accuracy: 0.8629\n",
      "Epoch 43/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3326 - accuracy: 0.8686 - val_loss: 0.3322 - val_accuracy: 0.8648\n",
      "Epoch 44/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3326 - accuracy: 0.8683 - val_loss: 0.3342 - val_accuracy: 0.8660\n",
      "Epoch 45/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3310 - accuracy: 0.8703 - val_loss: 0.3332 - val_accuracy: 0.8648\n",
      "Epoch 46/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3317 - accuracy: 0.8679 - val_loss: 0.3331 - val_accuracy: 0.8629\n",
      "Epoch 47/100\n",
      "536/536 [==============================] - 1s 1ms/step - loss: 0.3304 - accuracy: 0.8677 - val_loss: 0.3324 - val_accuracy: 0.8641\n",
      "Epoch 48/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3300 - accuracy: 0.8698 - val_loss: 0.3318 - val_accuracy: 0.8644\n",
      "Epoch 49/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3292 - accuracy: 0.8703 - val_loss: 0.3313 - val_accuracy: 0.8633\n",
      "Epoch 50/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3293 - accuracy: 0.8694 - val_loss: 0.3347 - val_accuracy: 0.8656\n",
      "Epoch 51/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3290 - accuracy: 0.8694 - val_loss: 0.3301 - val_accuracy: 0.8671\n",
      "Epoch 52/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3291 - accuracy: 0.8686 - val_loss: 0.3329 - val_accuracy: 0.8682\n",
      "Epoch 53/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3288 - accuracy: 0.8724 - val_loss: 0.3319 - val_accuracy: 0.8629\n",
      "Epoch 54/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3272 - accuracy: 0.8739 - val_loss: 0.3375 - val_accuracy: 0.8641\n",
      "Epoch 55/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3283 - accuracy: 0.8703 - val_loss: 0.3353 - val_accuracy: 0.8644\n",
      "Epoch 56/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3289 - accuracy: 0.8686 - val_loss: 0.3339 - val_accuracy: 0.8648\n",
      "Epoch 57/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3284 - accuracy: 0.8684 - val_loss: 0.3343 - val_accuracy: 0.8603\n",
      "Epoch 58/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3276 - accuracy: 0.8727 - val_loss: 0.3313 - val_accuracy: 0.8663\n",
      "Epoch 59/100\n",
      "536/536 [==============================] - 1s 1ms/step - loss: 0.3265 - accuracy: 0.8720 - val_loss: 0.3331 - val_accuracy: 0.8633\n",
      "Epoch 60/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3268 - accuracy: 0.8727 - val_loss: 0.3338 - val_accuracy: 0.8660\n",
      "Epoch 61/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3272 - accuracy: 0.8735 - val_loss: 0.3354 - val_accuracy: 0.8652\n",
      "Epoch 62/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3273 - accuracy: 0.8705 - val_loss: 0.3329 - val_accuracy: 0.8652\n",
      "Epoch 63/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3277 - accuracy: 0.8699 - val_loss: 0.3342 - val_accuracy: 0.8633\n",
      "Epoch 64/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3273 - accuracy: 0.8701 - val_loss: 0.3331 - val_accuracy: 0.8648\n",
      "Epoch 65/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3269 - accuracy: 0.8701 - val_loss: 0.3339 - val_accuracy: 0.8599\n",
      "Epoch 66/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3268 - accuracy: 0.8686 - val_loss: 0.3358 - val_accuracy: 0.8629\n",
      "Epoch 67/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3273 - accuracy: 0.8720 - val_loss: 0.3335 - val_accuracy: 0.8701\n",
      "Epoch 68/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3274 - accuracy: 0.8716 - val_loss: 0.3337 - val_accuracy: 0.8656\n",
      "Epoch 69/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3256 - accuracy: 0.8726 - val_loss: 0.3352 - val_accuracy: 0.8660\n",
      "Epoch 70/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3280 - accuracy: 0.8688 - val_loss: 0.3339 - val_accuracy: 0.8663\n",
      "Epoch 71/100\n",
      "536/536 [==============================] - 1s 1ms/step - loss: 0.3268 - accuracy: 0.8726 - val_loss: 0.3352 - val_accuracy: 0.8663\n",
      "Epoch 72/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3263 - accuracy: 0.8737 - val_loss: 0.3341 - val_accuracy: 0.8648\n",
      "Epoch 73/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3262 - accuracy: 0.8727 - val_loss: 0.3338 - val_accuracy: 0.8652\n",
      "Epoch 74/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3263 - accuracy: 0.8735 - val_loss: 0.3333 - val_accuracy: 0.8641\n",
      "Epoch 75/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3262 - accuracy: 0.8739 - val_loss: 0.3352 - val_accuracy: 0.8641\n",
      "Epoch 76/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3269 - accuracy: 0.8731 - val_loss: 0.3330 - val_accuracy: 0.8652\n",
      "Epoch 77/100\n",
      "536/536 [==============================] - 1s 1ms/step - loss: 0.3258 - accuracy: 0.8731 - val_loss: 0.3335 - val_accuracy: 0.8652\n",
      "Epoch 78/100\n",
      "536/536 [==============================] - 1s 3ms/step - loss: 0.3250 - accuracy: 0.8729 - val_loss: 0.3352 - val_accuracy: 0.8660\n",
      "Epoch 79/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3260 - accuracy: 0.8733 - val_loss: 0.3321 - val_accuracy: 0.8660\n",
      "Epoch 80/100\n",
      "536/536 [==============================] - 1s 1ms/step - loss: 0.3247 - accuracy: 0.8746 - val_loss: 0.3343 - val_accuracy: 0.8637\n",
      "Epoch 81/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3251 - accuracy: 0.8705 - val_loss: 0.3392 - val_accuracy: 0.8679\n",
      "Epoch 82/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3248 - accuracy: 0.8748 - val_loss: 0.3369 - val_accuracy: 0.8656\n",
      "Epoch 83/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3260 - accuracy: 0.8726 - val_loss: 0.3360 - val_accuracy: 0.8626\n",
      "Epoch 84/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3247 - accuracy: 0.8739 - val_loss: 0.3337 - val_accuracy: 0.8641\n",
      "Epoch 85/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3246 - accuracy: 0.8744 - val_loss: 0.3351 - val_accuracy: 0.8648\n",
      "Epoch 86/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3263 - accuracy: 0.8718 - val_loss: 0.3353 - val_accuracy: 0.8663\n",
      "Epoch 87/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3241 - accuracy: 0.8753 - val_loss: 0.3346 - val_accuracy: 0.8648\n",
      "Epoch 88/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3251 - accuracy: 0.8729 - val_loss: 0.3334 - val_accuracy: 0.8656\n",
      "Epoch 89/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3255 - accuracy: 0.8742 - val_loss: 0.3341 - val_accuracy: 0.8660\n",
      "Epoch 90/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3251 - accuracy: 0.8740 - val_loss: 0.3331 - val_accuracy: 0.8679\n",
      "Epoch 91/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3243 - accuracy: 0.8744 - val_loss: 0.3407 - val_accuracy: 0.8663\n",
      "Epoch 92/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3247 - accuracy: 0.8735 - val_loss: 0.3343 - val_accuracy: 0.8663\n",
      "Epoch 93/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3241 - accuracy: 0.8752 - val_loss: 0.3340 - val_accuracy: 0.8648\n",
      "Epoch 94/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3236 - accuracy: 0.8722 - val_loss: 0.3363 - val_accuracy: 0.8679\n",
      "Epoch 95/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3252 - accuracy: 0.8709 - val_loss: 0.3390 - val_accuracy: 0.8656\n",
      "Epoch 96/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3246 - accuracy: 0.8746 - val_loss: 0.3349 - val_accuracy: 0.8633\n",
      "Epoch 97/100\n",
      "536/536 [==============================] - 2s 3ms/step - loss: 0.3248 - accuracy: 0.8740 - val_loss: 0.3332 - val_accuracy: 0.8644\n",
      "Epoch 98/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3250 - accuracy: 0.8755 - val_loss: 0.3352 - val_accuracy: 0.8660\n",
      "Epoch 99/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3234 - accuracy: 0.8740 - val_loss: 0.3349 - val_accuracy: 0.8656\n",
      "Epoch 100/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3229 - accuracy: 0.8748 - val_loss: 0.3330 - val_accuracy: 0.8660\n"
     ]
    }
   ],
   "source": [
    "model_history=classifier.fit(X_train,y_train,validation_split=0.33,batch_size=10,epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.04111311],\n",
       "       [0.97700185],\n",
       "       [0.28759944],\n",
       "       ...,\n",
       "       [0.16015652],\n",
       "       [0.9615792 ],\n",
       "       [0.09881547]], dtype=float32)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=y_pred>0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       ...,\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8605"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1537,   52],\n",
       "       [ 227,  184]], dtype=int64)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.add(Dense(units=10,kernel_initializer='he_normal',activation='relu',input_dim=11))\n",
    "classifier.add(Dropout(0.3))\n",
    "classifier.add(Dense(units=20,kernel_initializer='he_normal',activation='relu'))\n",
    "classifier.add(Dropout(0.4))\n",
    "classifier.add(Dense(units=15,kernel_initializer='he_normal',activation='relu'))\n",
    "classifier.add(Dropout(0.2))\n",
    "classifier.add(Dense(units=1,kernel_initializer='glorot_uniform',activation='sigmoid'))\n",
    "classifier.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.5498 - accuracy: 0.7863 - val_loss: 0.4873 - val_accuracy: 0.7974\n",
      "Epoch 2/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.4224 - accuracy: 0.7962 - val_loss: 0.4132 - val_accuracy: 0.7974\n",
      "Epoch 3/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3924 - accuracy: 0.7962 - val_loss: 0.4393 - val_accuracy: 0.7974\n",
      "Epoch 4/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3862 - accuracy: 0.7964 - val_loss: 0.4095 - val_accuracy: 0.7974\n",
      "Epoch 5/100\n",
      "536/536 [==============================] - 1s 3ms/step - loss: 0.3812 - accuracy: 0.8255 - val_loss: 0.4057 - val_accuracy: 0.8644\n",
      "Epoch 6/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3804 - accuracy: 0.8612 - val_loss: 0.4110 - val_accuracy: 0.8641\n",
      "Epoch 7/100\n",
      "536/536 [==============================] - 1s 3ms/step - loss: 0.3846 - accuracy: 0.8580 - val_loss: 0.4285 - val_accuracy: 0.8614\n",
      "Epoch 8/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3677 - accuracy: 0.8614 - val_loss: 0.4125 - val_accuracy: 0.8607\n",
      "Epoch 9/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3757 - accuracy: 0.8651 - val_loss: 0.4106 - val_accuracy: 0.8595\n",
      "Epoch 10/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3746 - accuracy: 0.8608 - val_loss: 0.4012 - val_accuracy: 0.8618\n",
      "Epoch 11/100\n",
      "536/536 [==============================] - 1s 3ms/step - loss: 0.3749 - accuracy: 0.8600 - val_loss: 0.4498 - val_accuracy: 0.8455\n",
      "Epoch 12/100\n",
      "536/536 [==============================] - 1s 3ms/step - loss: 0.3722 - accuracy: 0.8625 - val_loss: 0.4269 - val_accuracy: 0.8444\n",
      "Epoch 13/100\n",
      "536/536 [==============================] - 1s 1ms/step - loss: 0.3688 - accuracy: 0.8604 - val_loss: 0.4150 - val_accuracy: 0.8595\n",
      "Epoch 14/100\n",
      "536/536 [==============================] - 1s 3ms/step - loss: 0.3708 - accuracy: 0.8589 - val_loss: 0.4199 - val_accuracy: 0.8417\n",
      "Epoch 15/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3708 - accuracy: 0.8610 - val_loss: 0.4284 - val_accuracy: 0.8406\n",
      "Epoch 16/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3705 - accuracy: 0.8658 - val_loss: 0.4348 - val_accuracy: 0.8565\n",
      "Epoch 17/100\n",
      "536/536 [==============================] - 1s 3ms/step - loss: 0.3660 - accuracy: 0.8647 - val_loss: 0.4130 - val_accuracy: 0.8501\n",
      "Epoch 18/100\n",
      "536/536 [==============================] - 1s 3ms/step - loss: 0.3688 - accuracy: 0.8602 - val_loss: 0.4201 - val_accuracy: 0.8493\n",
      "Epoch 19/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3665 - accuracy: 0.8627 - val_loss: 0.4034 - val_accuracy: 0.8429\n",
      "Epoch 20/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3656 - accuracy: 0.8586 - val_loss: 0.4737 - val_accuracy: 0.8323\n",
      "Epoch 21/100\n",
      "536/536 [==============================] - 1s 3ms/step - loss: 0.3686 - accuracy: 0.8571 - val_loss: 0.4930 - val_accuracy: 0.8209\n",
      "Epoch 22/100\n",
      "536/536 [==============================] - 2s 3ms/step - loss: 0.3664 - accuracy: 0.8612 - val_loss: 0.4123 - val_accuracy: 0.8444\n",
      "Epoch 23/100\n",
      "536/536 [==============================] - 1s 3ms/step - loss: 0.3637 - accuracy: 0.8610 - val_loss: 0.4156 - val_accuracy: 0.8466\n",
      "Epoch 24/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3665 - accuracy: 0.8608 - val_loss: 0.4951 - val_accuracy: 0.8205\n",
      "Epoch 25/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3616 - accuracy: 0.8670 - val_loss: 0.4157 - val_accuracy: 0.8603\n",
      "Epoch 26/100\n",
      "536/536 [==============================] - 1s 3ms/step - loss: 0.3628 - accuracy: 0.8628 - val_loss: 0.4090 - val_accuracy: 0.8425\n",
      "Epoch 27/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3649 - accuracy: 0.8623 - val_loss: 0.4564 - val_accuracy: 0.8330\n",
      "Epoch 28/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3645 - accuracy: 0.8636 - val_loss: 0.4085 - val_accuracy: 0.8542\n",
      "Epoch 29/100\n",
      "536/536 [==============================] - 2s 3ms/step - loss: 0.3670 - accuracy: 0.8606 - val_loss: 0.4317 - val_accuracy: 0.8493\n",
      "Epoch 30/100\n",
      "536/536 [==============================] - 1s 3ms/step - loss: 0.3648 - accuracy: 0.8630 - val_loss: 0.4313 - val_accuracy: 0.8527\n",
      "Epoch 31/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3595 - accuracy: 0.8630 - val_loss: 0.4268 - val_accuracy: 0.8444\n",
      "Epoch 32/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3636 - accuracy: 0.8651 - val_loss: 0.4379 - val_accuracy: 0.8493\n",
      "Epoch 33/100\n",
      "536/536 [==============================] - 1s 3ms/step - loss: 0.3645 - accuracy: 0.8630 - val_loss: 0.4477 - val_accuracy: 0.8413\n",
      "Epoch 34/100\n",
      "536/536 [==============================] - 1s 3ms/step - loss: 0.3688 - accuracy: 0.8615 - val_loss: 0.4565 - val_accuracy: 0.8296\n",
      "Epoch 35/100\n",
      "536/536 [==============================] - 1s 3ms/step - loss: 0.3641 - accuracy: 0.8627 - val_loss: 0.4662 - val_accuracy: 0.8338\n",
      "Epoch 36/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3665 - accuracy: 0.8627 - val_loss: 0.3957 - val_accuracy: 0.8637\n",
      "Epoch 37/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3599 - accuracy: 0.8643 - val_loss: 0.4000 - val_accuracy: 0.8531\n",
      "Epoch 38/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3643 - accuracy: 0.8628 - val_loss: 0.4398 - val_accuracy: 0.8402\n",
      "Epoch 39/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3644 - accuracy: 0.8645 - val_loss: 0.4553 - val_accuracy: 0.8349\n",
      "Epoch 40/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3630 - accuracy: 0.8602 - val_loss: 0.4782 - val_accuracy: 0.8088\n",
      "Epoch 41/100\n",
      "536/536 [==============================] - 1s 3ms/step - loss: 0.3635 - accuracy: 0.8651 - val_loss: 0.4346 - val_accuracy: 0.8383\n",
      "Epoch 42/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3652 - accuracy: 0.8608 - val_loss: 0.4637 - val_accuracy: 0.8270\n",
      "Epoch 43/100\n",
      "536/536 [==============================] - 1s 3ms/step - loss: 0.3653 - accuracy: 0.8623 - val_loss: 0.4662 - val_accuracy: 0.8398\n",
      "Epoch 44/100\n",
      "536/536 [==============================] - 2s 3ms/step - loss: 0.3588 - accuracy: 0.8690 - val_loss: 0.4407 - val_accuracy: 0.8444\n",
      "Epoch 45/100\n",
      "536/536 [==============================] - 2s 3ms/step - loss: 0.3610 - accuracy: 0.8677 - val_loss: 0.4495 - val_accuracy: 0.8364\n",
      "Epoch 46/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3645 - accuracy: 0.8638 - val_loss: 0.4654 - val_accuracy: 0.8296\n",
      "Epoch 47/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3629 - accuracy: 0.8668 - val_loss: 0.4529 - val_accuracy: 0.8379\n",
      "Epoch 48/100\n",
      "536/536 [==============================] - 2s 3ms/step - loss: 0.3622 - accuracy: 0.8658 - val_loss: 0.4512 - val_accuracy: 0.8334\n",
      "Epoch 49/100\n",
      "536/536 [==============================] - 1s 3ms/step - loss: 0.3636 - accuracy: 0.8645 - val_loss: 0.4844 - val_accuracy: 0.8277\n",
      "Epoch 50/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3654 - accuracy: 0.8651 - val_loss: 0.4339 - val_accuracy: 0.8523\n",
      "Epoch 51/100\n",
      "536/536 [==============================] - 1s 3ms/step - loss: 0.3588 - accuracy: 0.8638 - val_loss: 0.5019 - val_accuracy: 0.8122\n",
      "Epoch 52/100\n",
      "536/536 [==============================] - 1s 3ms/step - loss: 0.3625 - accuracy: 0.8656 - val_loss: 0.4220 - val_accuracy: 0.8493\n",
      "Epoch 53/100\n",
      "536/536 [==============================] - 1s 3ms/step - loss: 0.3606 - accuracy: 0.8664 - val_loss: 0.4647 - val_accuracy: 0.8379\n",
      "Epoch 54/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3619 - accuracy: 0.8636 - val_loss: 0.5036 - val_accuracy: 0.8345\n",
      "Epoch 55/100\n",
      "536/536 [==============================] - 1s 3ms/step - loss: 0.3562 - accuracy: 0.8679 - val_loss: 0.4123 - val_accuracy: 0.8531\n",
      "Epoch 56/100\n",
      "536/536 [==============================] - 1s 3ms/step - loss: 0.3591 - accuracy: 0.8656 - val_loss: 0.4305 - val_accuracy: 0.8410\n",
      "Epoch 57/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3622 - accuracy: 0.8655 - val_loss: 0.4413 - val_accuracy: 0.8383\n",
      "Epoch 58/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3650 - accuracy: 0.8597 - val_loss: 0.4759 - val_accuracy: 0.8296\n",
      "Epoch 59/100\n",
      "536/536 [==============================] - 1s 3ms/step - loss: 0.3590 - accuracy: 0.8666 - val_loss: 0.4224 - val_accuracy: 0.8523\n",
      "Epoch 60/100\n",
      "536/536 [==============================] - 2s 3ms/step - loss: 0.3564 - accuracy: 0.8688 - val_loss: 0.4393 - val_accuracy: 0.8504\n",
      "Epoch 61/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3611 - accuracy: 0.8645 - val_loss: 0.4626 - val_accuracy: 0.8311\n",
      "Epoch 62/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3596 - accuracy: 0.8658 - val_loss: 0.4830 - val_accuracy: 0.8281\n",
      "Epoch 63/100\n",
      "536/536 [==============================] - 1s 3ms/step - loss: 0.3611 - accuracy: 0.8640 - val_loss: 0.4617 - val_accuracy: 0.8330\n",
      "Epoch 64/100\n",
      "536/536 [==============================] - 2s 3ms/step - loss: 0.3593 - accuracy: 0.8651 - val_loss: 0.4566 - val_accuracy: 0.8410\n",
      "Epoch 65/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3608 - accuracy: 0.8653 - val_loss: 0.4290 - val_accuracy: 0.8527\n",
      "Epoch 66/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3582 - accuracy: 0.8666 - val_loss: 0.4782 - val_accuracy: 0.8262\n",
      "Epoch 67/100\n",
      "536/536 [==============================] - 1s 3ms/step - loss: 0.3573 - accuracy: 0.8666 - val_loss: 0.4216 - val_accuracy: 0.8470\n",
      "Epoch 68/100\n",
      "536/536 [==============================] - 2s 3ms/step - loss: 0.3555 - accuracy: 0.8658 - val_loss: 0.4688 - val_accuracy: 0.8319\n",
      "Epoch 69/100\n",
      "536/536 [==============================] - 2s 3ms/step - loss: 0.3610 - accuracy: 0.8677 - val_loss: 0.4687 - val_accuracy: 0.8345\n",
      "Epoch 70/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3602 - accuracy: 0.8664 - val_loss: 0.4709 - val_accuracy: 0.8273\n",
      "Epoch 71/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3594 - accuracy: 0.8670 - val_loss: 0.4639 - val_accuracy: 0.8289\n",
      "Epoch 72/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3619 - accuracy: 0.8666 - val_loss: 0.4528 - val_accuracy: 0.8425\n",
      "Epoch 73/100\n",
      "536/536 [==============================] - 1s 3ms/step - loss: 0.3560 - accuracy: 0.8666 - val_loss: 0.4062 - val_accuracy: 0.8542\n",
      "Epoch 74/100\n",
      "536/536 [==============================] - 1s 1ms/step - loss: 0.3607 - accuracy: 0.8612 - val_loss: 0.4837 - val_accuracy: 0.8194\n",
      "Epoch 75/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3600 - accuracy: 0.8664 - val_loss: 0.4741 - val_accuracy: 0.8285\n",
      "Epoch 76/100\n",
      "536/536 [==============================] - 2s 3ms/step - loss: 0.3632 - accuracy: 0.8668 - val_loss: 0.4707 - val_accuracy: 0.8326\n",
      "Epoch 77/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3580 - accuracy: 0.8703 - val_loss: 0.4241 - val_accuracy: 0.8504\n",
      "Epoch 78/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3580 - accuracy: 0.8649 - val_loss: 0.4515 - val_accuracy: 0.8323\n",
      "Epoch 79/100\n",
      "536/536 [==============================] - 2s 3ms/step - loss: 0.3622 - accuracy: 0.8670 - val_loss: 0.4423 - val_accuracy: 0.8432\n",
      "Epoch 80/100\n",
      "536/536 [==============================] - 2s 3ms/step - loss: 0.3558 - accuracy: 0.8647 - val_loss: 0.4249 - val_accuracy: 0.8535\n",
      "Epoch 81/100\n",
      "536/536 [==============================] - 2s 3ms/step - loss: 0.3546 - accuracy: 0.8692 - val_loss: 0.4747 - val_accuracy: 0.8247\n",
      "Epoch 82/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3555 - accuracy: 0.8683 - val_loss: 0.4894 - val_accuracy: 0.8069\n",
      "Epoch 83/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3549 - accuracy: 0.8683 - val_loss: 0.4665 - val_accuracy: 0.8289\n",
      "Epoch 84/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3576 - accuracy: 0.8627 - val_loss: 0.4533 - val_accuracy: 0.8292\n",
      "Epoch 85/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3606 - accuracy: 0.8649 - val_loss: 0.4992 - val_accuracy: 0.8171\n",
      "Epoch 86/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3592 - accuracy: 0.8628 - val_loss: 0.4619 - val_accuracy: 0.8334\n",
      "Epoch 87/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3572 - accuracy: 0.8668 - val_loss: 0.4689 - val_accuracy: 0.8304\n",
      "Epoch 88/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3534 - accuracy: 0.8714 - val_loss: 0.4276 - val_accuracy: 0.8519\n",
      "Epoch 89/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3552 - accuracy: 0.8649 - val_loss: 0.4627 - val_accuracy: 0.8281\n",
      "Epoch 90/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3529 - accuracy: 0.8671 - val_loss: 0.4470 - val_accuracy: 0.8432\n",
      "Epoch 91/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3550 - accuracy: 0.8662 - val_loss: 0.4999 - val_accuracy: 0.8186\n",
      "Epoch 92/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3539 - accuracy: 0.8666 - val_loss: 0.5064 - val_accuracy: 0.7940\n",
      "Epoch 93/100\n",
      "536/536 [==============================] - 1s 3ms/step - loss: 0.3528 - accuracy: 0.8694 - val_loss: 0.4579 - val_accuracy: 0.8372\n",
      "Epoch 94/100\n",
      "536/536 [==============================] - 2s 3ms/step - loss: 0.3529 - accuracy: 0.8671 - val_loss: 0.4842 - val_accuracy: 0.8186\n",
      "Epoch 95/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3579 - accuracy: 0.8658 - val_loss: 0.4403 - val_accuracy: 0.8421\n",
      "Epoch 96/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3541 - accuracy: 0.8649 - val_loss: 0.4909 - val_accuracy: 0.8190\n",
      "Epoch 97/100\n",
      "536/536 [==============================] - 2s 3ms/step - loss: 0.3559 - accuracy: 0.8656 - val_loss: 0.4363 - val_accuracy: 0.8455\n",
      "Epoch 98/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3521 - accuracy: 0.8686 - val_loss: 0.4413 - val_accuracy: 0.8429\n",
      "Epoch 99/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3563 - accuracy: 0.8668 - val_loss: 0.4924 - val_accuracy: 0.8126\n",
      "Epoch 100/100\n",
      "536/536 [==============================] - 1s 2ms/step - loss: 0.3559 - accuracy: 0.8696 - val_loss: 0.5104 - val_accuracy: 0.8126\n"
     ]
    }
   ],
   "source": [
    "model_history=classifier.fit(X_train,y_train,validation_split=0.33,batch_size=10,epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=y_pred>0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1322,  267],\n",
       "       [ 116,  295]], dtype=int64)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8085"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
